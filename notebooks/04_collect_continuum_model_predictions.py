import numpy as np
import pandas as pd

from scipy.interpolate import interp1d
from notebooks.models import * 

"""
Collects the continuum model predictions for all sites and saves them to CSV files.
"""

current_date = pd.Timestamp.now().date().strftime("%d-%m-%Y")

# Load the site data
site_data = pd.read_csv('results/processed_balesdent_2018.csv')
turnover_14C = pd.read_csv('results/all_sites_14C_turnover.csv')

#%% Gamma model

# load the gamma model parameters to generate predictions
gamma_params = pd.read_csv('results/03_calibrate_models/gamma_model_optimization_results.csv')

print("Generating gamma model predictions...")
predictions = []
for i, row in gamma_params.iterrows():
    model = GammaDisKin(a=row['a'], b=row['b'])
    predictions.append(model.cdfA(site_data.loc[i, 'Duration_labeling']))
predictions = np.array(predictions)
# Save the model predictions
np.savetxt(f'results/04_model_predictions/gamma_{current_date}.csv', predictions)

#%% Power-law model

# load the power-law parameters
power_law_params = pd.read_csv('results/03_calibrate_models/powerlaw_model_optimization_results.csv')

print("Generating power-law model predictions...")
predictions = []
for i, row in power_law_params.iterrows():
    model = PowerLawDisKin(tau_0=row['tau_0'], tau_inf=row['tau_inf'])
    predictions.append(model.cdfA(site_data.loc[i, 'Duration_labeling']))
predictions = np.array(predictions)
# Save the model predictions
np.savetxt(f'results/04_model_predictions/power_law_{current_date}.csv', predictions)

#%% Generalized Power-law model

# load the power-law parameters
general_power_law_params = pd.read_csv('results/03_calibrate_models/general_powerlaw_model_optimization_results.csv')

print("Generating generalized power-law model predictions...")
predictions = []
for i, row in general_power_law_params.iterrows():
    model = GeneralPowerLawDisKin(tau_0=row['tau_0'], tau_inf=row['tau_inf'])
    predictions.append(model.cdfA(site_data.loc[i, 'Duration_labeling']))
predictions = np.array(predictions)
# Save the model predictions
np.savetxt(f'results/04_model_predictions/general_power_law_{current_date}.csv', predictions)


#%% Lognormal model

# read lognormal cdfs that were generated by the julia script - 04b_lognormal_predictions.jl
print("Generating lognormal model predictions...")
lognormal_cdfs = pd.read_csv('results/04_model_predictions/04b_lognormal_cdfs.csv')
ts = lognormal_cdfs.columns.astype(float).values
predictions = []
for i, row in site_data.iterrows():
    site_cdf = interp1d(ts, lognormal_cdfs.loc[i, :].values / turnover_14C.loc[i, 'turnover'])
    predictions.append(site_cdf(row['Duration_labeling']))
predictions = np.array(predictions)
# Save the model predictions
np.savetxt(f'results/04_model_predictions/lognormal_{current_date}.csv', predictions)
